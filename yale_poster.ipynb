{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ac0aebfa-936e-416a-bdba-b70e5d5a0864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "import cv2\n",
    "import llama_index\n",
    "import PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f866c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Fritz/Workspace/Yale_Visiting_Day_Poster'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f57bad91-7fae-48a9-af12-cc91d9259fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data(CK=True, JAFFE=True, FER2013=True):\n",
    "\n",
    "    emo_dict = {\"anger\":0, \"contempt\":0, \"disgust\":0, \"fear\":0, \"happiness\":0, \"neutral\":0, \"sadness\":0, \"surprise\":0}\n",
    "    list_paths = []\n",
    "\n",
    "    # CK+ load\n",
    "    if CK:\n",
    "        for emotion in [\"anger\", \"contempt\", \"disgust\", \"fear\", \"happiness\", \"neutral\", \"sadness\", \"surprise\"]:\n",
    "            emo_folder_path = \"../Polygence/Datasets/CK+/\" + emotion\n",
    "            for pic_file in glob.glob(os.path.join(emo_folder_path, \"*png\")):\n",
    "                list_paths.append([emotion, pic_file])\n",
    "\n",
    "    # JAFFE load\n",
    "    if JAFFE:\n",
    "        for pic_file in glob.glob(os.path.join(\"../Polygence/Datasets/JAFFE\", \"*tiff\")):\n",
    "            if \"AN\" in pic_file[26:]:\n",
    "                list_paths.append([\"anger\", pic_file])\n",
    "            elif \"DI\" in pic_file[26:]:\n",
    "                list_paths.append([\"disgust\", pic_file])\n",
    "            elif \"FE\" in pic_file[26:]:\n",
    "                list_paths.append([\"fear\", pic_file])\n",
    "            elif \"HA\" in pic_file[26:]:\n",
    "                list_paths.append([\"happiness\", pic_file])\n",
    "            elif \"NE\" in pic_file[26:]:\n",
    "                list_paths.append([\"neutral\", pic_file])\n",
    "            elif \"SA\" in pic_file[26:]:\n",
    "                list_paths.append([\"sadness\", pic_file])\n",
    "            else:\n",
    "                list_paths.append([\"surprise\", pic_file])\n",
    "\n",
    "    #FER-2013\n",
    "    if FER2013:\n",
    "        FER_emo_dict = {0:\"anger\", 1:\"disgust\", 2:\"fear\", 3:\"happiness\", 4:\"neutral\", 5:\"sadness\", 6:\"surprise\"}\n",
    "        for set in [\"test/\", \"train/\"]:\n",
    "            root = \"../Polygence/Datasets/FER2013/\" + set\n",
    "            for index, emotion in enumerate([\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]):\n",
    "                emo_folder_path = root + emotion\n",
    "                for pic_file in glob.glob(os.path.join(emo_folder_path, \"*jpg\")):\n",
    "                    list_paths.append([FER_emo_dict[index], pic_file])   \n",
    "    for (a,b) in list_paths:\n",
    "        emo_dict[a] +=1\n",
    "    print(emo_dict)\n",
    "    return list_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "041b10f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n",
      "['anger', '../Polygence/Datasets/JAFFE/MK.AN3.127.tiff']\n",
      "[['anger', '../Polygence/Datasets/JAFFE/MK.AN3.127.tiff'], ['fear', '../Polygence/Datasets/JAFFE/MK.NE1.113.tiff'], ['anger', '../Polygence/Datasets/JAFFE/YM.AN3.63.tiff'], ['fear', '../Polygence/Datasets/JAFFE/MK.SA1.119.tiff'], ['anger', '../Polygence/Datasets/JAFFE/KA.AN1.39.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KA.SU2.37.tiff'], ['fear', '../Polygence/Datasets/JAFFE/YM.NE2.50.tiff'], ['fear', '../Polygence/Datasets/JAFFE/TM.HA2.181.tiff'], ['fear', '../Polygence/Datasets/JAFFE/NA.FE2.218.tiff'], ['fear', '../Polygence/Datasets/JAFFE/YM.NE3.51.tiff'], ['disgust', '../Polygence/Datasets/JAFFE/MK.DI1.128.tiff'], ['anger', '../Polygence/Datasets/JAFFE/YM.AN2.62.tiff'], ['anger', '../Polygence/Datasets/JAFFE/KL.AN2.168.tiff'], ['fear', '../Polygence/Datasets/JAFFE/YM.HA2.53.tiff'], ['anger', '../Polygence/Datasets/JAFFE/NA.AN2.212.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KM.SA5.13.tiff'], ['fear', '../Polygence/Datasets/JAFFE/UY.FE1.152.tiff'], ['anger', '../Polygence/Datasets/JAFFE/UY.AN2.147.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KR.NE1.71.tiff'], ['fear', '../Polygence/Datasets/JAFFE/NA.HA3.204.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KM.HA2.5.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KA.FE1.45.tiff'], ['disgust', '../Polygence/Datasets/JAFFE/KL.DI4.173.tiff'], ['fear', '../Polygence/Datasets/JAFFE/TM.SA1.184.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KA.HA1.29.tiff'], ['disgust', '../Polygence/Datasets/JAFFE/YM.DI3.66.tiff'], ['fear', '../Polygence/Datasets/JAFFE/TM.NE1.177.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KR.HA2.75.tiff'], ['disgust', '../Polygence/Datasets/JAFFE/UY.DI1.149.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KL.SA1.161.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KL.FE2.175.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KM.SU3.16.tiff'], ['anger', '../Polygence/Datasets/JAFFE/KL.AN3.169.tiff'], ['anger', '../Polygence/Datasets/JAFFE/NA.AN3.213.tiff'], ['fear', '../Polygence/Datasets/JAFFE/YM.FE2.68.tiff'], ['fear', '../Polygence/Datasets/JAFFE/NA.FE3.219.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KR.SU3.82.tiff'], ['anger', '../Polygence/Datasets/JAFFE/NM.AN3.106.tiff'], ['fear', '../Polygence/Datasets/JAFFE/UY.NE3.136.tiff'], ['fear', '../Polygence/Datasets/JAFFE/YM.FE3.69.tiff'], ['disgust', '../Polygence/Datasets/JAFFE/NA.DI2.215.tiff'], ['fear', '../Polygence/Datasets/JAFFE/KA.NE1.26.tiff'], ['disgust', '../Polygence/Datasets/JAFFE/KL.DI1.170.tiff'], ['anger', '../Polygence/Datasets/JAFFE/MK.AN2.126.tiff'], ['anger', '../Polygence/Datasets/JAFFE/TM.AN2.191.tiff'], ['fear', '../Polygence/Datasets/JAFFE/YM.FE4.70.tiff'], ['disgust', '../Polygence/Datasets/JAFFE/KL.DI3.172.tiff'], ['disgust', '../Polygence/Datasets/JAFFE/KM.DI1.20.tiff'], ['anger', '../Polygence/Datasets/JAFFE/NM.AN1.104.tiff'], ['fear', '../Polygence/Datasets/JAFFE/NM.FE2.111.tiff']]\n"
     ]
    }
   ],
   "source": [
    "#print(list_paths)\n",
    "print(len(list_paths))\n",
    "print(list_paths[0])\n",
    "print(list_paths[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e962cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, [emo, file] in enumerate(list_paths):\n",
    "#         image = cv2.imread(file, 0)\n",
    "#         # Convert the BGR image to RGB before processing.\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e078999e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Ollama call failed with status code 400. Details: {\"error\":\"unsupported image format\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#plt_img_base64(image_b64)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m llm_with_image_context \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind(images\u001b[38;5;241m=\u001b[39m[image_b64])\n\u001b[0;32m---> 47\u001b[0m \u001b[43mllm_with_image_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is the facial emotion expressed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# messages = [\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#     SystemMessage(\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#         content=\"You are a helpful assistant that translates English to French.\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# # print(str(messages))\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# llm(str(messages))\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/yale_poster/lib/python3.9/site-packages/langchain_core/runnables/base.py:4458\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   4453\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4454\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4455\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4456\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 4458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4459\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4460\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4462\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/yale_poster/lib/python3.9/site-packages/langchain_core/language_models/llms.py:248\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    245\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    246\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 248\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    260\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/yale_poster/lib/python3.9/site-packages/langchain_core/language_models/llms.py:569\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    563\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    567\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    568\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/yale_poster/lib/python3.9/site-packages/langchain_core/language_models/llms.py:748\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    732\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    733\u001b[0m         )\n\u001b[1;32m    734\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    735\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    736\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m         )\n\u001b[1;32m    747\u001b[0m     ]\n\u001b[0;32m--> 748\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/yale_poster/lib/python3.9/site-packages/langchain_core/language_models/llms.py:606\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    605\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    607\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/.conda/envs/yale_poster/lib/python3.9/site-packages/langchain_core/language_models/llms.py:593\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    585\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    590\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    592\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 593\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    601\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    602\u001b[0m         )\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.conda/envs/yale_poster/lib/python3.9/site-packages/langchain_community/llms/ollama.py:421\u001b[0m, in \u001b[0;36mOllama._generate\u001b[0;34m(self, prompts, stop, images, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m--> 421\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/.conda/envs/yale_poster/lib/python3.9/site-packages/langchain_community/llms/ollama.py:330\u001b[0m, in \u001b[0;36m_OllamaCommon._stream_with_aggregation\u001b[0;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stream_with_aggregation\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    328\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GenerationChunk:\n\u001b[1;32m    329\u001b[0m     final_chunk: Optional[GenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[1;32m    332\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _stream_response_to_generation_chunk(stream_resp)\n",
      "File \u001b[0;32m~/.conda/envs/yale_poster/lib/python3.9/site-packages/langchain_community/llms/ollama.py:172\u001b[0m, in \u001b[0;36m_OllamaCommon._create_generate_stream\u001b[0;34m(self, prompt, stop, images, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    166\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    170\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    171\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpayload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/api/generate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/yale_poster/lib/python3.9/site-packages/langchain_community/llms/ollama.py:253\u001b[0m, in \u001b[0;36m_OllamaCommon._create_stream\u001b[0;34m(self, api_url, payload, stop, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m         optional_detail \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m--> 253\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOllama call failed with status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Details: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptional_detail\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m         )\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines(decode_unicode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Ollama call failed with status code 400. Details: {\"error\":\"unsupported image format\"}"
     ]
    }
   ],
   "source": [
    "# os.environ['OPENAI_API_KEY']=##",
    "# os.environ['OPENAI_API_BASE']=##",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "llm = Ollama(model=\"bakllava\")\n",
    "\n",
    "def convert_to_base64(pil_image):\n",
    "    \"\"\"\n",
    "    Convert PIL images to Base64 encoded strings\n",
    "\n",
    "    :param pil_image: PIL image\n",
    "    :return: Re-sized Base64 string\n",
    "    \"\"\"\n",
    "\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"tiff\")  # You can change the format if needed\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    \"\"\"\n",
    "    Display base64 encoded string as image\n",
    "\n",
    "    :param img_base64:  Base64 string\n",
    "    \"\"\"\n",
    "    # Create an HTML img tag with the base64 string as the source\n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "    # Display the image by rendering the HTML\n",
    "    display(HTML(image_html))\n",
    "\n",
    "\n",
    "file_path = list_paths[150][1]\n",
    "print(list_paths[150][0])\n",
    "pil_image = Image.open(file_path)\n",
    "image_b64 = convert_to_base64(pil_image)\n",
    "#plt_img_base64(image_b64)\n",
    "\n",
    "llm_with_image_context = llm.bind(images=[image_b64])\n",
    "llm_with_image_context.invoke(\"What is the facial emotion expressed\")\n",
    "\n",
    "# messages = [\n",
    "#     SystemMessage(\n",
    "#         content=\"You are a helpful assistant that translates English to French.\"\n",
    "#     ),\n",
    "#     HumanMessage(content=\"I love programming.\"),\n",
    "# ]\n",
    "# # print(str(messages))\n",
    "# llm(str(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "df257f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def classify_emotion(file_path, display=False):\n",
    "    output_parser = StrOutputParser()\n",
    "    pil_image = Image.open(file_path)\n",
    "    image_b64 = convert_to_base64(pil_image)\n",
    "    if display:\n",
    "        plt_img_base64(image_b64)\n",
    "\n",
    "    llm = ChatOllama(model=\"bakllava\")\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are going to recognize the facial emotion of the given picture. Here is some guiding information. Anger is communicated by lowered eyebrows, widened eyes, firmly pressed lips, and flared nostrils. Disgust brings a wrinkled nose, raised upper lip, and protruding lower lip. Fear raises the eyebrows, opens the eyes widely, and parts the lips slightly. In contrast, happiness crinkles the eye corners into crow's feet as the mouth raises into a smile. A neutral expression has relaxed, unfurrowed features with a closed mouth. Sadness raises the inner eyebrows while turning the lips downward into a frown. Surprise raises the eyebrows high, opens the eyes and mouth wide.Based on given face's characteristics, please identify the facial emotion of the image as one of the following: anger, contempt, disgust, fear, happiness, neutral, sadness, or surprise. Answer in one word.\"\n",
    "        ),\n",
    "\n",
    "        HumanMessage(image_documents=image_b64, content=\"Here is an image of a person's face\")\n",
    "        # AIMessage(content=\"disgust\"),\n",
    "        # AIMessage(content=\"happiness\"),\n",
    "        # AIMessage(content=\"fear\"),\n",
    "        # AIMessage(content=\"neutral\"),\n",
    "        # AIMessage(content=\"surprise\"),\n",
    "        # AIMessage(content=\"sadness\")\n",
    "    ]\n",
    "     #HumanMessage(image_documents=image_b64, content=\"Here is an image of a person's face\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "\n",
    "    chain = prompt | llm | output_parser\n",
    "\n",
    "\n",
    "    output_messages = chain.invoke({\"input\": prompt, \"context\": image_b64})\n",
    "\n",
    "    return output_messages.strip(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7246a1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 45, 'contempt': 18, 'disgust': 59, 'fear': 25, 'happiness': 69, 'neutral': 593, 'sadness': 28, 'surprise': 83}\n",
      "anger 0 0\n"
     ]
    }
   ],
   "source": [
    "# Test for FER on JAFFE\n",
    "\n",
    "CK_paths = find_data(CK=True, JAFFE=False, FER2013=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "angie = 0\n",
    "disgust = 0\n",
    "fe = 0\n",
    "ha = 0\n",
    "ne = 0\n",
    "sa = 0\n",
    "su = 0\n",
    "\n",
    "# guesses[n][0] = correct label, guesses[n][1] = predicted label\n",
    "guesses = []\n",
    "\n",
    "emo_hat = classify_emotion(CK_paths[0][1], display=False)\n",
    "print(CK_paths[0][0], emo_hat, emo_hat.lower())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fef7f03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "1 11\n",
      "1 12\n",
      "1 13\n",
      "1 14\n",
      "1 15\n",
      "1 16\n",
      "1 17\n",
      "1 18\n",
      "1 19\n",
      "1 20\n",
      "1 21\n",
      "1 22\n",
      "1 23\n",
      "1 24\n",
      "1 25\n",
      "1 26\n",
      "1 27\n",
      "1 28\n",
      "1 29\n",
      "1 30\n",
      "1 31\n",
      "1 32\n",
      "2 33\n",
      "3 34\n",
      "3 35\n",
      "3 36\n",
      "3 37\n",
      "4 38\n",
      "4 39\n",
      "4 40\n",
      "4 41\n",
      "4 42\n",
      "4 43\n",
      "4 44\n",
      "4 45\n",
      "4 46\n",
      "4 47\n",
      "4 48\n",
      "4 49\n",
      "4 50\n",
      "5 51\n",
      "5 52\n",
      "5 53\n",
      "5 54\n",
      "6 55\n",
      "6 56\n",
      "6 57\n",
      "6 58\n",
      "6 59\n",
      "6 60\n",
      "6 61\n",
      "6 62\n",
      "6 63\n",
      "6 64\n",
      "6 65\n",
      "6 66\n",
      "6 67\n",
      "6 68\n",
      "6 69\n",
      "6 70\n",
      "6 71\n",
      "7 72\n",
      "7 73\n",
      "7 74\n",
      "7 75\n",
      "7 76\n",
      "7 77\n",
      "7 78\n",
      "7 79\n",
      "7 80\n",
      "7 81\n",
      "7 82\n",
      "7 83\n",
      "7 84\n",
      "7 85\n",
      "7 86\n",
      "7 87\n",
      "7 88\n",
      "7 89\n",
      "7 90\n",
      "7 91\n",
      "7 92\n",
      "7 93\n",
      "7 94\n",
      "7 95\n",
      "7 96\n",
      "7 97\n",
      "7 98\n",
      "7 99\n",
      "7 100\n",
      "7 101\n",
      "7 102\n",
      "7 103\n",
      "7 104\n",
      "7 105\n",
      "7 106\n",
      "7 107\n",
      "7 108\n",
      "7 109\n",
      "7 110\n",
      "7 111\n",
      "7 112\n",
      "7 113\n",
      "7 114\n",
      "7 115\n",
      "7 116\n",
      "7 117\n",
      "7 118\n",
      "7 119\n",
      "7 120\n",
      "7 121\n",
      "7 122\n",
      "7 123\n",
      "8 124\n",
      "8 125\n",
      "8 126\n",
      "8 127\n",
      "8 128\n",
      "8 129\n",
      "8 130\n",
      "8 131\n",
      "8 132\n",
      "8 133\n",
      "8 134\n",
      "8 135\n",
      "8 136\n",
      "8 137\n",
      "8 138\n",
      "8 139\n",
      "8 140\n",
      "8 141\n",
      "8 142\n",
      "8 143\n",
      "8 144\n",
      "8 145\n",
      "8 146\n",
      "8 147\n",
      "8 148\n",
      "8 149\n",
      "8 150\n",
      "8 151\n",
      "8 152\n",
      "8 153\n",
      "8 154\n",
      "8 155\n",
      "8 156\n",
      "8 157\n",
      "8 158\n",
      "9 159\n",
      "9 160\n",
      "9 161\n",
      "9 162\n",
      "9 163\n",
      "9 164\n",
      "9 165\n",
      "9 166\n",
      "9 167\n",
      "10 168\n",
      "10 169\n",
      "10 170\n",
      "10 171\n",
      "10 172\n",
      "10 173\n",
      "10 174\n",
      "10 175\n",
      "10 176\n",
      "10 177\n",
      "10 178\n",
      "10 179\n",
      "10 180\n",
      "11 181\n",
      "11 182\n",
      "11 183\n",
      "11 184\n",
      "11 185\n",
      "11 186\n",
      "11 187\n",
      "11 188\n",
      "11 189\n",
      "11 190\n",
      "11 191\n",
      "11 192\n",
      "11 193\n",
      "11 194\n",
      "11 195\n",
      "11 196\n",
      "11 197\n",
      "11 198\n",
      "11 199\n",
      "11 200\n",
      "11 201\n",
      "11 202\n",
      "11 203\n",
      "11 204\n",
      "11 205\n",
      "12 206\n",
      "12 207\n",
      "12 208\n",
      "12 209\n",
      "12 210\n",
      "12 211\n",
      "12 212\n",
      "12 213\n",
      "[16, 9, 9, 11, 10, 11, 12]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 3, 4, 3, 3, 4, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# anger, disgust, fear, happiness, neutral, sadness, surprise\n",
    "# 30 29 32 31 30 31 30\n",
    "matrix = [[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0]]\n",
    "# column = correct, row= guessed\n",
    "emo_dict = {\"anger\":0, \"disgust\":1, \"fear\":2, \"happiness\":3, \"neutral\":4, \"sadness\":5, \"surprise\":6}\n",
    "\n",
    "for idx, [emo, file] in enumerate(JAFFE_paths):\n",
    "    emo_hat = classify_emotion(file, display=False)\n",
    "    if emo_hat == emo:\n",
    "        correct += 1\n",
    "    #guesses.append([emo.lower(), emo_hat.lower()])\n",
    "    if emo_hat.lower() in emo_dict.keys():\n",
    "        matrix[emo_dict[emo_hat.lower()]][emo_dict[emo]] +=1\n",
    "    total +=1\n",
    "    print(correct, total)\n",
    "    \n",
    "for i in matrix:\n",
    "    print(i)\n",
    "print(guesses)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf64ddc2",
   "metadata": {},
   "source": [
    "1 1\n",
    "1 2\n",
    "2 3\n",
    "2 4\n",
    "3 5\n",
    "3 6\n",
    "3 7\n",
    "3 8\n",
    "3 9\n",
    "3 10\n",
    "3 11\n",
    "4 12\n",
    "5 13\n",
    "5 14\n",
    "6 15\n",
    "6 16\n",
    "6 17\n",
    "6 18\n",
    "6 19\n",
    "6 20\n",
    "6 21\n",
    "6 22\n",
    "6 23\n",
    "6 24\n",
    "6 25\n",
    "6 26\n",
    "6 27\n",
    "6 28\n",
    "6 29\n",
    "6 30\n",
    "6 31\n",
    "6 32\n",
    "7 33\n",
    "8 34\n",
    "8 35\n",
    "8 36\n",
    "8 37\n",
    "9 38\n",
    "9 39\n",
    "9 40\n",
    "9 41\n",
    "9 42\n",
    "9 43\n",
    "10 44\n",
    "11 45\n",
    "11 46\n",
    "11 47\n",
    "11 48\n",
    "11 49\n",
    "11 50\n",
    "11 51\n",
    "11 52\n",
    "11 53\n",
    "11 54\n",
    "11 55\n",
    "11 56\n",
    "11 57\n",
    "11 58\n",
    "11 59\n",
    "12 60\n",
    "12 61\n",
    "13 62\n",
    "13 63\n",
    "13 64\n",
    "13 65\n",
    "13 66\n",
    "13 67\n",
    "13 68\n",
    "13 69\n",
    "14 70\n",
    "14 71\n",
    "15 72\n",
    "15 73\n",
    "15 74\n",
    "15 75\n",
    "15 76\n",
    "15 77\n",
    "15 78\n",
    "15 79\n",
    "15 80\n",
    "15 81\n",
    "15 82\n",
    "15 83\n",
    "15 84\n",
    "15 85\n",
    "15 86\n",
    "15 87\n",
    "15 88\n",
    "15 89\n",
    "15 90\n",
    "15 91\n",
    "15 92\n",
    "15 93\n",
    "15 94\n",
    "15 95\n",
    "15 96\n",
    "15 97\n",
    "15 98\n",
    "15 99\n",
    "15 100\n",
    "15 101\n",
    "15 102\n",
    "15 103\n",
    "15 104\n",
    "15 105\n",
    "15 106\n",
    "15 107\n",
    "15 108\n",
    "15 109\n",
    "15 110\n",
    "15 111\n",
    "15 112\n",
    "15 113\n",
    "15 114\n",
    "15 115\n",
    "15 116\n",
    "16 117\n",
    "16 118\n",
    "16 119\n",
    "17 120\n",
    "17 121\n",
    "17 122\n",
    "17 123\n",
    "18 124\n",
    "18 125\n",
    "18 126\n",
    "18 127\n",
    "18 128\n",
    "18 129\n",
    "18 130\n",
    "18 131\n",
    "19 132\n",
    "19 133\n",
    "19 134\n",
    "19 135\n",
    "19 136\n",
    "20 137\n",
    "20 138\n",
    "20 139\n",
    "20 140\n",
    "20 141\n",
    "20 142\n",
    "20 143\n",
    "20 144\n",
    "20 145\n",
    "20 146\n",
    "20 147\n",
    "20 148\n",
    "20 149\n",
    "20 150\n",
    "20 151\n",
    "20 152\n",
    "20 153\n",
    "20 154\n",
    "20 155\n",
    "20 156\n",
    "20 157\n",
    "20 158\n",
    "21 159\n",
    "21 160\n",
    "21 161\n",
    "21 162\n",
    "21 163\n",
    "21 164\n",
    "21 165\n",
    "21 166\n",
    "21 167\n",
    "22 168\n",
    "22 169\n",
    "22 170\n",
    "22 171\n",
    "23 172\n",
    "23 173\n",
    "23 174\n",
    "23 175\n",
    "23 176\n",
    "23 177\n",
    "23 178\n",
    "23 179\n",
    "23 180\n",
    "23 181\n",
    "23 182\n",
    "23 183\n",
    "23 184\n",
    "23 185\n",
    "23 186\n",
    "23 187\n",
    "23 188\n",
    "23 189\n",
    "23 190\n",
    "23 191\n",
    "23 192\n",
    "23 193\n",
    "23 194\n",
    "23 195\n",
    "23 196\n",
    "23 197\n",
    "23 198\n",
    "23 199\n",
    "23 200\n",
    "23 201\n",
    "23 202\n",
    "23 203\n",
    "23 204\n",
    "23 205\n",
    "24 206\n",
    "24 207\n",
    "24 208\n",
    "24 209\n",
    "24 210\n",
    "24 211\n",
    "24 212\n",
    "24 213\n",
    "[['anger', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['anger', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', ' anger'], ['anger', ' anger'], ['fear', ' anger'], ['fear', ' anger'], ['fear', ' anger'], ['fear', ' anger'], ['disgust', ' anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['anger', 'anger'], ['anger', 'anger'], ['fear', 'user: anger'], ['disgust', 'user: anger'], ['disgust', 'user: anger'], ['anger', 'user: anger'], ['fear', 'user: anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['disgust', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', ' angel madeline phipps 1902-1985'], ['fear', ' angel madeline phipps 1902-1985'], ['disgust', 'user: anger'], ['fear', 'user: anger'], ['disgust', 'user: anger'], ['fear', 'user: anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'user: anger'], ['fear', 'user: anger'], ['fear', 'user: anger'], ['fear', 'user: anger'], ['fear', 'user: anger'], ['fear', ' anger'], ['fear', ' anger'], ['disgust', ' anger'], ['fear', ' anger'], ['fear', ' anger'], ['fear', ' anger'], ['anger', 'user: surprise'], ['anger', 'user: surprise'], ['disgust', 'user: surprise'], ['fear', 'user: surprise'], ['fear', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['disgust', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['anger', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger'], ['fear', 'anger']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6bd65a",
   "metadata": {},
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "from llama_index.multi_modal_llms.gemini import GeminiMultiModal\n",
    "from llama_index.core.program import MultiModalLLMCompletionProgram\n",
    "from llama_index.core.output_parsers import PydanticOutputParser\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "GOOGLE_API_KEY = #",
    "MODEL_NAME = \"models/gemini-pro-vision\"\n",
    "\n",
    "gemini_llm = GeminiMultiModal(\n",
    "        api_key=GOOGLE_API_KEY,\n",
    "        model_name=MODEL_NAME\n",
    "    )\n",
    "\n",
    "image_documents = SimpleDirectoryReader(\n",
    "        input_files=[list_paths[0][1]]\n",
    "    ).load_data()\n",
    "\n",
    "class Analysis(BaseModel):\n",
    "    \"\"\"analysis questioning\"\"\"\n",
    "    number_people: int\n",
    "    describe_the_face: str\n",
    "    eyes: str\n",
    "    eyebrows: str\n",
    "    mouth: str\n",
    "    sentiment: str\n",
    "#    Please_analyze_the_sentiment_of_person_Focus_on_identifying_the_emotion_based_on_the_facial_features_of_the_person_Avoid_subjective_opinions_or_commentary_unrelated_to_the_person_itself:str\n",
    "    \n",
    "\n",
    "\n",
    "llm_program = MultiModalLLMCompletionProgram.from_defaults(\n",
    "        output_parser=PydanticOutputParser(output_cls=Analysis),\n",
    "        image_documents=image_documents,\n",
    "        prompt_template_str=\"Please analyze the sentiment of person. Focus on identifying the emotion based on the facial features of the person. Avoid subjective opinions or commentary unrelated to the person itself. Do not respond neutral.\",\n",
    "        multi_modal_llm=gemini_llm,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "response = llm_program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060e58d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yale_poster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
